# Dockerfile for CUDA (NVIDIA GPU) support
# Base image with CUDA 12.1 support
FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04

# Set environment variables early to avoid warnings
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app \
    CUDA_VISIBLE_DEVICES=0 \
    PIP_NO_WARN_SCRIPT_LOCATION=1 \
    PIP_ROOT_USER_ACTION=ignore

# Set working directory
WORKDIR /app

# Install system dependencies in a single layer to reduce image size
# apt-utils prevents debconf warnings
RUN apt-get update && apt-get install -y --no-install-recommends \
    apt-utils \
    python3.11 \
    python3.11-dev \
    python3-pip \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgtk-3-0 \
    libavcodec-dev \
    libavformat-dev \
    libswscale-dev \
    libv4l-dev \
    libxvidcore-dev \
    libx264-dev \
    libjpeg-dev \
    libpng-dev \
    libtiff-dev \
    libatlas-base-dev \
    libtbb2 \
    libtbb-dev \
    wget \
    curl \
    git \
    && ln -s /usr/bin/python3.11 /usr/bin/python \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Upgrade pip and install PyTorch with CUDA support in one layer
RUN pip install --no-cache-dir --root-user-action=ignore \
    --upgrade pip setuptools wheel \
    && pip install --no-cache-dir --root-user-action=ignore \
    torch>=2.0.0 \
    torchvision>=0.15.0 \
    --index-url https://download.pytorch.org/whl/cu121

# Copy requirements file and install dependencies
COPY gcp-build/app-code/requirements-cuda-docker.txt /app/requirements-cuda-docker.txt
RUN pip install --no-cache-dir --root-user-action=ignore -r requirements-cuda-docker.txt

# Copy application code (this should be last as it changes most frequently)
# Copy everything from app-code directory to /app in container
COPY gcp-build/app-code/ /app/

# Ensure directories exist (they should already exist from COPY, but ensure they're there)
RUN mkdir -p /app/models /app/data /app/outputs /app/processed_videos

# Set CUDA environment variables
ENV NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Expose ports
EXPOSE 8000 8501

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD python -c "import torch; assert torch.cuda.is_available()" || exit 1

# Default command
CMD ["python", "launch_gui.py"]
